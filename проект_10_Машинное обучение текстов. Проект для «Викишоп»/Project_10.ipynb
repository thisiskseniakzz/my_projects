{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#проверим-баланс-классов\" data-toc-modified-id=\"проверим-баланс-классов-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>проверим баланс классов</a></span></li><li><span><a href=\"#Лемматизация-текста-и-последующее-удаление-стоп-слов\" data-toc-modified-id=\"Лемматизация-текста-и-последующее-удаление-стоп-слов-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Лемматизация текста и последующее удаление стоп-слов</a></span></li><li><span><a href=\"#Разделение-данных\" data-toc-modified-id=\"Разделение-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Разделение данных</a></span></li></ul></li><li><span><a href=\"#Векторизация-(TF-IDF)\" data-toc-modified-id=\"Векторизация-(TF-IDF)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Векторизация (TF-IDF)</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-пайплайна\" data-toc-modified-id=\"Подготовка-пайплайна-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Подготовка пайплайна</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорты библиотек \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from tqdm import tqdm \n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer \n",
    "from transformers import pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from pymystem3 import Mystem\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "# Константы\n",
    "RANDOM_STATE = 42\n",
    "N_ITER = 30\n",
    "CV_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в данных не обнаружено, типы данных соответствующие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### проверим баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898388\n",
      "1    0.101612\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_dist = df['toxic'].value_counts(normalize=True)\n",
    "print(class_dist)\n",
    "\n",
    "class_dist.plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Распределение классов')\n",
    "plt.xticks([0, 1], ['Нетоксичные', 'Токсичные'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация текста и последующее удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "100%|██████████| 159292/159292 [08:39<00:00, 306.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка:\n",
      "оригинал: Why are you implying that I am a Muslim? If someone doesn't support cr...\n",
      "лемма: imply muslim someone support criminal fanatic like shiv sena remain hi...\n",
      "\n",
      "оригинал: March 2011 (UTC)\n",
      "\n",
      "Actually I'll address the concerns (as the site admi...\n",
      "лемма: march utc actually address concern site admin site truly much ad link ...\n",
      "\n",
      "оригинал: I am primarily a reader rather than a writer of the encyclopaedia. I h...\n",
      "лемма: primarily reader rather writer encyclopaedia neither time interest nee...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Скачивание необходимых данных\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Конвертация POS-тегов для WordNetLemmatizer\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN \n",
    "\n",
    "def lemmatize_english_text(text):\n",
    "    \"\"\"Лемматизация английского текста с учетом POS-тегов\"\"\"\n",
    "    try:\n",
    "        # Очистка текста\n",
    "        text = re.sub(r'[^a-zA-Z ]', ' ', str(text))\n",
    "        words = word_tokenize(text.lower())\n",
    "        \n",
    "        # Получение POSтегов\n",
    "        pos_tags = pos_tag(words)\n",
    "        \n",
    "        # Лемматизация с фильтрацией\n",
    "        lemmas = []\n",
    "        for word, tag in pos_tags:\n",
    "            if word not in stop_words and len(word) > 2:\n",
    "                pos = get_wordnet_pos(tag)\n",
    "                lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "                lemmas.append(lemma)\n",
    "                \n",
    "        return ' '.join(lemmas)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "        return ''\n",
    "\n",
    "\n",
    "df['lemm_text'] = df['text'].progress_apply(lemmatize_english_text)\n",
    "\n",
    "# Проверка \n",
    "print(\"Проверка:\")\n",
    "sample = df.sample(3)\n",
    "for orig, lemm in zip(sample['text'], sample['lemm_text']):\n",
    "    print(f\"оригинал: {orig[:70]}...\")\n",
    "    print(f\"лемма: {lemm[:70]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['toxic'], test_size=0.2, random_state=RANDOM_STATE, stratify=df['toxic']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.9s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  19.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  20.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=50; total time=  22.4s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=50; total time=  34.4s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=50; total time=  32.6s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=50; total time=  33.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=50; total time=  35.7s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=50; total time=  34.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=100; total time=  26.7s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=100; total time=  27.8s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=100; total time=  26.4s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=100; total time=  28.5s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=100; total time=  25.9s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  29.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  25.9s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  26.9s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  27.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=241; total time=  19.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=6, model__n_estimators=285; total time=  22.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=6, model__n_estimators=285; total time=  23.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=6, model__n_estimators=285; total time=  22.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=6, model__n_estimators=285; total time=  22.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=6, model__n_estimators=285; total time=  22.6s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.0, model__penalty=l1, model__solver=liblinear; total time=   2.2s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.0, model__penalty=l1, model__solver=liblinear; total time=   2.2s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.0, model__penalty=l1, model__solver=liblinear; total time=   2.6s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.0, model__penalty=l1, model__solver=liblinear; total time=   2.3s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.0, model__penalty=l1, model__solver=liblinear; total time=   2.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=5, model__n_estimators=100; total time=  35.8s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=5, model__n_estimators=100; total time=  35.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=5, model__n_estimators=100; total time=  37.7s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=5, model__n_estimators=100; total time=  39.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=5, model__n_estimators=100; total time=  37.5s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=5, model__n_estimators=50; total time=  28.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=5, model__n_estimators=50; total time=  28.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=5, model__n_estimators=50; total time=  28.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=5, model__n_estimators=50; total time=  27.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=5, model__n_estimators=50; total time=  26.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=104; total time=  34.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=104; total time=  35.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=104; total time=  34.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=104; total time=  35.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=104; total time=  35.3s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.714285714285714, model__penalty=l1, model__solver=liblinear; total time=   2.3s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.714285714285714, model__penalty=l1, model__solver=liblinear; total time=   2.6s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.714285714285714, model__penalty=l1, model__solver=liblinear; total time=   2.3s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.714285714285714, model__penalty=l1, model__solver=liblinear; total time=   2.7s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=5.714285714285714, model__penalty=l1, model__solver=liblinear; total time=   2.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=50; total time=  20.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=50; total time=  20.6s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=50; total time=  19.8s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=50; total time=  19.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.1, model__max_depth=3, model__n_estimators=50; total time=  21.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  25.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  28.6s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  26.3s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  26.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  26.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=58; total time=   4.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=58; total time=   4.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=58; total time=   4.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=58; total time=   4.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=58; total time=   4.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=3, model__n_estimators=133; total time= 5.1min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=3, model__n_estimators=133; total time= 5.1min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=3, model__n_estimators=133; total time= 5.1min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=3, model__n_estimators=133; total time= 5.2min\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=100; total time=  57.4s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=100; total time=  50.1s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=100; total time=  50.5s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=100; total time=  51.2s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=7, model__n_estimators=100; total time=  49.0s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.5, model__penalty=l1, model__solver=liblinear; total time=   2.9s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.5, model__penalty=l1, model__solver=liblinear; total time=   2.5s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.5, model__penalty=l1, model__solver=liblinear; total time=   2.9s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.5, model__penalty=l1, model__solver=liblinear; total time=   3.0s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.5, model__penalty=l1, model__solver=liblinear; total time=   2.5s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  30.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  32.5s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  26.0s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  25.6s\n",
      "[CV] END model=LGBMClassifier(random_state=42), model__learning_rate=0.05, model__max_depth=3, model__n_estimators=100; total time=  26.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=7, model__n_estimators=183; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=7, model__n_estimators=183; total time=  14.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=7, model__n_estimators=183; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=7, model__n_estimators=183; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=7, model__n_estimators=183; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=5, model__n_estimators=103; total time=   8.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=5, model__n_estimators=103; total time=   8.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=5, model__n_estimators=103; total time=   8.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=5, model__n_estimators=103; total time=   8.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=5, model__n_estimators=103; total time=   8.1s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=10.0, model__penalty=l2, model__solver=liblinear; total time=   2.4s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=10.0, model__penalty=l2, model__solver=liblinear; total time=   2.1s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=10.0, model__penalty=l2, model__solver=liblinear; total time=   2.4s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=10.0, model__penalty=l2, model__solver=liblinear; total time=   2.1s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=10.0, model__penalty=l2, model__solver=liblinear; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=239; total time=  18.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=239; total time=  19.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=239; total time=  18.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=239; total time=  18.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=10, model__min_samples_split=3, model__n_estimators=239; total time=  19.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=9, model__n_estimators=64; total time=  20.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=9, model__n_estimators=64; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=9, model__n_estimators=64; total time=  20.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=9, model__n_estimators=64; total time=  20.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=9, model__n_estimators=64; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=298; total time= 1.7min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=298; total time= 1.7min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=298; total time= 1.7min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=5, model__n_estimators=298; total time= 1.7min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=9, model__n_estimators=286; total time= 9.7min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=9, model__n_estimators=286; total time= 9.9min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=9, model__n_estimators=286; total time= 9.9min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=9, model__n_estimators=286; total time= 9.8min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=6, model__n_estimators=73; total time=  25.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=6, model__n_estimators=73; total time=  26.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=6, model__n_estimators=73; total time=  25.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=6, model__n_estimators=73; total time=  25.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=30, model__min_samples_split=6, model__n_estimators=73; total time=  24.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=5, model__n_estimators=237; total time= 8.8min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=5, model__n_estimators=237; total time= 8.7min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=5, model__n_estimators=237; total time= 8.5min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=5, model__n_estimators=237; total time= 8.6min\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, random_state=42), model__max_depth=None, model__min_samples_split=5, model__n_estimators=237; total time= 8.9min\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.857142857142858, model__penalty=l1, model__solver=liblinear; total time=   2.6s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.857142857142858, model__penalty=l1, model__solver=liblinear; total time=   3.0s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.857142857142858, model__penalty=l1, model__solver=liblinear; total time=   2.6s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.857142857142858, model__penalty=l1, model__solver=liblinear; total time=   3.0s\n",
      "[CV] END model=LogisticRegression(max_iter=1000, random_state=42), model__C=7.857142857142858, model__penalty=l1, model__solver=liblinear; total time=   2.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('model',\n",
       "                                              LogisticRegression(random_state=42))]),\n",
       "                   n_iter=30, n_jobs=-1,\n",
       "                   param_distributions=[{'model': [LogisticRegression(C=5.0,\n",
       "                                                                      max_iter=1000,\n",
       "                                                                      penalty='l1',\n",
       "                                                                      random_state=42,\n",
       "                                                                      solver='liblinear')],\n",
       "                                         'model__C': array([ 5.        ,  5.35714286,  5.71428571,  6.07142857,  6.42857143,\n",
       "        6.78571429,  7.14285714,  7.5       ,  7.85714286,  8.21428571...\n",
       "                                         'model__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7fb2d94d4c10>,\n",
       "                                         'model__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7fb2d95f88e0>},\n",
       "                                        {'model': [LGBMClassifier(random_state=42)],\n",
       "                                         'model__learning_rate': [0.1, 0.05],\n",
       "                                         'model__max_depth': [3, 5, 7],\n",
       "                                         'model__n_estimators': [50, 100]}],\n",
       "                   random_state=42, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_final = Pipeline([\n",
    "    ('model', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    # LogisticRegression\n",
    "    {\n",
    "        'model': [LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)],\n",
    "        'model__C': np.linspace(5, 10, 15),\n",
    "        'model__penalty': ['l1','l2'],\n",
    "        'model__solver':['liblinear'],\n",
    "    },\n",
    "    \n",
    "    # RandomForest\n",
    "    {\n",
    "        'model': [RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)],\n",
    "        'model__n_estimators': randint(50, 300),\n",
    "        'model__max_depth': [None, 10, 30],\n",
    "        'model__min_samples_split': randint(2, 10)\n",
    "    },\n",
    "    # LGBM\n",
    "    {\n",
    "        'model': [LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1)],\n",
    "        'model__max_depth': [3, 5, 7],  \n",
    "        'model__learning_rate': [0.1, 0.05],  \n",
    "        'model__n_estimators': [50, 100]\n",
    "    }]\n",
    "    \n",
    "\n",
    "# Инициализация RandomizedSearchCV\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    estimator=pipe_final,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=N_ITER,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring='f1',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "randomized_search.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и параметры:\n",
      " Pipeline(steps=[('model',\n",
      "                 LogisticRegression(C=5.0, max_iter=1000, penalty='l1',\n",
      "                                    random_state=42, solver='liblinear'))])\n",
      "F1: 0.7773727494323849\n",
      "\n",
      "F1 (test): 0.7796\n"
     ]
    }
   ],
   "source": [
    "# оценка качества\n",
    "print('Лучшая модель и параметры:\\n', randomized_search.best_estimator_)\n",
    "print('F1:', randomized_search.best_score_)\n",
    "\n",
    "y_test_pred = randomized_search.best_estimator_.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "print(f'\\nF1 (test): {f1_score(y_test, y_test_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте мы закрепили свои знания по применению машинного обучения для анализа текста, в данном проекте использовали классический метод векторизации текстов TF-IDF, а далее использвоали самые распространенные модели МО: Логистическая регрессия, Случайный лес и LGBM.\n",
    "\n",
    "Предобработка текста вклбчала в себя этап \"Лемматизации\", на котором мы привели все твиты к нижнему регистру, очистили от лишних символов, а также удалили стоп-слова.\n",
    "\n",
    "Определена лучшая модель - это LogisticRegression со следующими параметрами: \n",
    "- **Pipeline(steps=[('model',\n",
    "                 LogisticRegression(C=5.0, max_iter=1000, penalty='l1',\n",
    "                                    random_state=42, solver='liblinear'))])**\n",
    "                                    \n",
    "Значение метрики F1 для тренировочных данных составило **0.778 < 0.75**, а на тестовых - **0.78 < 0.75**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1212,
    "start_time": "2025-07-06T20:43:14.215Z"
   },
   {
    "duration": 1052,
    "start_time": "2025-07-06T20:43:34.395Z"
   },
   {
    "duration": 93,
    "start_time": "2025-07-06T20:43:56.694Z"
   },
   {
    "duration": 15,
    "start_time": "2025-07-06T20:44:03.011Z"
   },
   {
    "duration": 36,
    "start_time": "2025-07-06T20:44:26.901Z"
   },
   {
    "duration": 22,
    "start_time": "2025-07-06T21:04:58.573Z"
   },
   {
    "duration": 51,
    "start_time": "2025-07-08T19:38:34.028Z"
   },
   {
    "duration": 1162,
    "start_time": "2025-07-08T19:38:40.764Z"
   },
   {
    "duration": 986,
    "start_time": "2025-07-08T19:38:41.928Z"
   },
   {
    "duration": 15,
    "start_time": "2025-07-08T19:38:42.916Z"
   },
   {
    "duration": 47,
    "start_time": "2025-07-08T19:38:42.933Z"
   },
   {
    "duration": 68,
    "start_time": "2025-07-08T19:38:47.215Z"
   },
   {
    "duration": 256,
    "start_time": "2025-07-08T19:39:12.195Z"
   },
   {
    "duration": 84604,
    "start_time": "2025-07-08T19:41:37.333Z"
   },
   {
    "duration": 10,
    "start_time": "2025-07-08T20:30:52.606Z"
   },
   {
    "duration": 16,
    "start_time": "2025-07-08T20:31:08.585Z"
   },
   {
    "duration": 83462,
    "start_time": "2025-07-08T20:31:12.940Z"
   },
   {
    "duration": 11,
    "start_time": "2025-07-08T20:33:16.104Z"
   },
   {
    "duration": 61,
    "start_time": "2025-07-08T20:33:25.354Z"
   },
   {
    "duration": 7830,
    "start_time": "2025-07-08T20:33:27.704Z"
   },
   {
    "duration": 8000,
    "start_time": "2025-07-08T20:34:53.262Z"
   },
   {
    "duration": 804,
    "start_time": "2025-07-08T20:44:33.037Z"
   },
   {
    "duration": 2195,
    "start_time": "2025-07-08T20:44:42.452Z"
   },
   {
    "duration": 200,
    "start_time": "2025-07-08T20:45:02.503Z"
   },
   {
    "duration": 36,
    "start_time": "2025-07-08T20:45:19.265Z"
   },
   {
    "duration": 22,
    "start_time": "2025-07-08T20:46:32.302Z"
   },
   {
    "duration": 7,
    "start_time": "2025-07-08T20:46:37.126Z"
   },
   {
    "duration": 21,
    "start_time": "2025-07-08T20:46:38.436Z"
   },
   {
    "duration": 21,
    "start_time": "2025-07-08T20:59:43.277Z"
   },
   {
    "duration": 20,
    "start_time": "2025-07-08T21:00:16.244Z"
   },
   {
    "duration": 6,
    "start_time": "2025-07-08T21:00:35.553Z"
   },
   {
    "duration": 24,
    "start_time": "2025-07-08T21:00:36.626Z"
   },
   {
    "duration": 7,
    "start_time": "2025-07-08T21:00:46.828Z"
   },
   {
    "duration": 24,
    "start_time": "2025-07-08T21:00:50.091Z"
   },
   {
    "duration": 23,
    "start_time": "2025-07-08T21:01:07.350Z"
   },
   {
    "duration": 27,
    "start_time": "2025-07-08T21:02:36.332Z"
   },
   {
    "duration": 33,
    "start_time": "2025-07-08T21:03:07.128Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-08T21:05:37.597Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-08T21:05:37.598Z"
   },
   {
    "duration": 4,
    "start_time": "2025-07-08T21:06:27.964Z"
   },
   {
    "duration": 1077,
    "start_time": "2025-07-08T21:35:56.397Z"
   },
   {
    "duration": 950,
    "start_time": "2025-07-08T21:35:57.476Z"
   },
   {
    "duration": 13,
    "start_time": "2025-07-08T21:35:58.428Z"
   },
   {
    "duration": 47,
    "start_time": "2025-07-08T21:35:58.443Z"
   },
   {
    "duration": 83990,
    "start_time": "2025-07-08T21:35:58.492Z"
   },
   {
    "duration": 77,
    "start_time": "2025-07-08T21:37:22.484Z"
   },
   {
    "duration": 8112,
    "start_time": "2025-07-08T21:37:22.562Z"
   },
   {
    "duration": 2933,
    "start_time": "2025-07-08T21:37:30.676Z"
   },
   {
    "duration": 1419693,
    "start_time": "2025-07-08T21:37:33.611Z"
   },
   {
    "duration": 1078,
    "start_time": "2025-07-08T22:01:28.224Z"
   },
   {
    "duration": 1153,
    "start_time": "2025-07-08T22:01:39.727Z"
   },
   {
    "duration": 1019,
    "start_time": "2025-07-08T22:01:40.882Z"
   },
   {
    "duration": 13,
    "start_time": "2025-07-08T22:01:41.903Z"
   },
   {
    "duration": 120,
    "start_time": "2025-07-08T22:01:41.918Z"
   },
   {
    "duration": 86145,
    "start_time": "2025-07-08T22:01:42.040Z"
   },
   {
    "duration": 78,
    "start_time": "2025-07-08T22:03:08.187Z"
   },
   {
    "duration": 8542,
    "start_time": "2025-07-08T22:03:08.267Z"
   },
   {
    "duration": 2968,
    "start_time": "2025-07-08T22:03:16.811Z"
   },
   {
    "duration": 329,
    "start_time": "2025-07-08T22:03:19.780Z"
   },
   {
    "duration": 1127,
    "start_time": "2025-07-08T22:26:08.847Z"
   },
   {
    "duration": 948,
    "start_time": "2025-07-08T22:26:09.976Z"
   },
   {
    "duration": 15,
    "start_time": "2025-07-08T22:26:10.925Z"
   },
   {
    "duration": 76,
    "start_time": "2025-07-08T22:26:10.941Z"
   },
   {
    "duration": 81558,
    "start_time": "2025-07-08T22:26:11.019Z"
   },
   {
    "duration": 69,
    "start_time": "2025-07-08T22:27:32.578Z"
   },
   {
    "duration": 8081,
    "start_time": "2025-07-08T22:27:32.649Z"
   },
   {
    "duration": 2866,
    "start_time": "2025-07-08T22:27:40.731Z"
   },
   {
    "duration": 309,
    "start_time": "2025-07-08T22:27:43.598Z"
   },
   {
    "duration": 1166,
    "start_time": "2025-07-08T22:29:30.373Z"
   },
   {
    "duration": 966,
    "start_time": "2025-07-08T22:29:31.541Z"
   },
   {
    "duration": 13,
    "start_time": "2025-07-08T22:29:32.509Z"
   },
   {
    "duration": 72,
    "start_time": "2025-07-08T22:29:32.523Z"
   },
   {
    "duration": 82380,
    "start_time": "2025-07-08T22:29:32.597Z"
   },
   {
    "duration": 70,
    "start_time": "2025-07-08T22:30:54.979Z"
   },
   {
    "duration": 8092,
    "start_time": "2025-07-08T22:30:55.060Z"
   },
   {
    "duration": 2967,
    "start_time": "2025-07-08T22:31:03.153Z"
   },
   {
    "duration": 2590874,
    "start_time": "2025-07-08T22:31:06.122Z"
   },
   {
    "duration": 1178,
    "start_time": "2025-07-10T20:36:59.796Z"
   },
   {
    "duration": 965,
    "start_time": "2025-07-10T20:37:00.976Z"
   },
   {
    "duration": 15,
    "start_time": "2025-07-10T20:37:01.943Z"
   },
   {
    "duration": 166,
    "start_time": "2025-07-10T20:37:01.959Z"
   },
   {
    "duration": 85937,
    "start_time": "2025-07-10T20:37:02.127Z"
   },
   {
    "duration": 71,
    "start_time": "2025-07-10T20:38:28.065Z"
   },
   {
    "duration": 8542,
    "start_time": "2025-07-10T20:38:28.138Z"
   },
   {
    "duration": 3491,
    "start_time": "2025-07-10T20:38:36.682Z"
   },
   {
    "duration": 437,
    "start_time": "2025-07-10T20:38:40.175Z"
   },
   {
    "duration": 88,
    "start_time": "2025-07-10T20:41:02.575Z"
   },
   {
    "duration": 163,
    "start_time": "2025-07-10T20:41:34.612Z"
   },
   {
    "duration": 139953,
    "start_time": "2025-07-10T20:43:52.765Z"
   },
   {
    "duration": 328614,
    "start_time": "2025-07-10T20:46:35.872Z"
   },
   {
    "duration": 189,
    "start_time": "2025-07-10T20:59:57.337Z"
   },
   {
    "duration": 1170,
    "start_time": "2025-07-10T21:00:55.271Z"
   },
   {
    "duration": 1022,
    "start_time": "2025-07-10T21:00:56.443Z"
   },
   {
    "duration": 18,
    "start_time": "2025-07-10T21:00:57.467Z"
   },
   {
    "duration": 43,
    "start_time": "2025-07-10T21:00:57.488Z"
   },
   {
    "duration": 88670,
    "start_time": "2025-07-10T21:00:57.534Z"
   },
   {
    "duration": 76,
    "start_time": "2025-07-10T21:02:26.206Z"
   },
   {
    "duration": 8555,
    "start_time": "2025-07-10T21:02:26.283Z"
   },
   {
    "duration": 3768,
    "start_time": "2025-07-10T21:02:34.840Z"
   },
   {
    "duration": 135618,
    "start_time": "2025-07-10T21:02:38.611Z"
   },
   {
    "duration": 75,
    "start_time": "2025-07-10T21:04:54.232Z"
   },
   {
    "duration": 183520,
    "start_time": "2025-07-10T21:08:16.115Z"
   },
   {
    "duration": 927738,
    "start_time": "2025-07-10T21:11:24.233Z"
   },
   {
    "duration": 20,
    "start_time": "2025-07-10T21:43:40.298Z"
   },
   {
    "duration": 22,
    "start_time": "2025-07-10T21:44:31.913Z"
   },
   {
    "duration": 18,
    "start_time": "2025-07-10T21:59:48.178Z"
   },
   {
    "duration": 17,
    "start_time": "2025-07-10T22:02:52.744Z"
   },
   {
    "duration": 102,
    "start_time": "2025-07-10T22:09:15.639Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.742Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.744Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.746Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.747Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.749Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.750Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.752Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:09:15.753Z"
   },
   {
    "duration": 4175,
    "start_time": "2025-07-10T22:09:46.381Z"
   },
   {
    "duration": 907,
    "start_time": "2025-07-10T22:09:50.558Z"
   },
   {
    "duration": 20,
    "start_time": "2025-07-10T22:09:51.466Z"
   },
   {
    "duration": 120,
    "start_time": "2025-07-10T22:09:51.487Z"
   },
   {
    "duration": 85028,
    "start_time": "2025-07-10T22:09:51.609Z"
   },
   {
    "duration": 323,
    "start_time": "2025-07-10T22:11:16.638Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:11:16.963Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:11:16.964Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:11:16.965Z"
   },
   {
    "duration": 4243,
    "start_time": "2025-07-10T22:11:41.369Z"
   },
   {
    "duration": 898,
    "start_time": "2025-07-10T22:11:45.614Z"
   },
   {
    "duration": 15,
    "start_time": "2025-07-10T22:11:46.514Z"
   },
   {
    "duration": 116,
    "start_time": "2025-07-10T22:11:46.531Z"
   },
   {
    "duration": 84854,
    "start_time": "2025-07-10T22:11:46.649Z"
   },
   {
    "duration": 76,
    "start_time": "2025-07-10T22:13:11.505Z"
   },
   {
    "duration": 8038,
    "start_time": "2025-07-10T22:13:11.583Z"
   },
   {
    "duration": 332,
    "start_time": "2025-07-10T22:13:19.623Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:13:19.958Z"
   },
   {
    "duration": 4297,
    "start_time": "2025-07-10T22:31:21.930Z"
   },
   {
    "duration": 892,
    "start_time": "2025-07-10T22:31:26.229Z"
   },
   {
    "duration": 14,
    "start_time": "2025-07-10T22:31:27.123Z"
   },
   {
    "duration": 57,
    "start_time": "2025-07-10T22:31:27.139Z"
   },
   {
    "duration": 86695,
    "start_time": "2025-07-10T22:31:27.198Z"
   },
   {
    "duration": 81,
    "start_time": "2025-07-10T22:32:53.895Z"
   },
   {
    "duration": 8241,
    "start_time": "2025-07-10T22:32:53.978Z"
   },
   {
    "duration": 372876,
    "start_time": "2025-07-10T22:33:02.221Z"
   },
   {
    "duration": 0,
    "start_time": "2025-07-10T22:39:15.098Z"
   },
   {
    "duration": 794392,
    "start_time": "2025-07-10T22:41:26.563Z"
   },
   {
    "duration": 18,
    "start_time": "2025-07-10T22:57:54.896Z"
   },
   {
    "duration": 4828,
    "start_time": "2025-07-12T21:41:56.685Z"
   },
   {
    "duration": 973,
    "start_time": "2025-07-12T21:42:01.515Z"
   },
   {
    "duration": 16,
    "start_time": "2025-07-12T21:42:02.489Z"
   },
   {
    "duration": 53,
    "start_time": "2025-07-12T21:42:02.507Z"
   },
   {
    "duration": 475,
    "start_time": "2025-07-12T21:42:04.809Z"
   },
   {
    "duration": 4564,
    "start_time": "2025-07-12T22:12:06.234Z"
   },
   {
    "duration": 937,
    "start_time": "2025-07-12T22:12:10.800Z"
   },
   {
    "duration": 28,
    "start_time": "2025-07-12T22:12:11.738Z"
   },
   {
    "duration": 36,
    "start_time": "2025-07-12T22:12:11.767Z"
   },
   {
    "duration": 268,
    "start_time": "2025-07-12T22:12:11.805Z"
   },
   {
    "duration": 92254,
    "start_time": "2025-07-12T22:12:12.075Z"
   },
   {
    "duration": 80,
    "start_time": "2025-07-12T22:13:44.332Z"
   },
   {
    "duration": 8773,
    "start_time": "2025-07-12T22:13:44.414Z"
   },
   {
    "duration": 898642,
    "start_time": "2025-07-12T22:13:53.189Z"
   },
   {
    "duration": 27,
    "start_time": "2025-07-12T22:28:51.833Z"
   },
   {
    "duration": 2712,
    "start_time": "2025-07-12T22:43:57.638Z"
   },
   {
    "duration": 4541,
    "start_time": "2025-07-12T22:46:27.884Z"
   },
   {
    "duration": 943,
    "start_time": "2025-07-12T22:46:32.427Z"
   },
   {
    "duration": 16,
    "start_time": "2025-07-12T22:46:33.372Z"
   },
   {
    "duration": 58,
    "start_time": "2025-07-12T22:46:33.389Z"
   },
   {
    "duration": 264,
    "start_time": "2025-07-12T22:46:33.449Z"
   },
   {
    "duration": 575059,
    "start_time": "2025-07-12T22:46:33.715Z"
   },
   {
    "duration": 68,
    "start_time": "2025-07-12T22:56:08.775Z"
   },
   {
    "duration": 8677,
    "start_time": "2025-07-12T22:56:08.845Z"
   },
   {
    "duration": 888072,
    "start_time": "2025-07-12T22:56:17.524Z"
   },
   {
    "duration": 19,
    "start_time": "2025-07-12T23:11:05.598Z"
   },
   {
    "duration": 107,
    "start_time": "2025-07-12T23:29:38.331Z"
   },
   {
    "duration": 5293,
    "start_time": "2025-07-12T23:49:32.743Z"
   },
   {
    "duration": 937,
    "start_time": "2025-07-12T23:49:38.038Z"
   },
   {
    "duration": 17,
    "start_time": "2025-07-12T23:49:38.977Z"
   },
   {
    "duration": 40,
    "start_time": "2025-07-12T23:49:38.996Z"
   },
   {
    "duration": 279,
    "start_time": "2025-07-12T23:49:39.038Z"
   },
   {
    "duration": 567088,
    "start_time": "2025-07-12T23:49:39.319Z"
   },
   {
    "duration": 90,
    "start_time": "2025-07-12T23:59:06.410Z"
   },
   {
    "duration": 8631,
    "start_time": "2025-07-12T23:59:06.502Z"
   },
   {
    "duration": 52,
    "start_time": "2025-07-13T09:08:46.409Z"
   },
   {
    "duration": 6219,
    "start_time": "2025-07-13T09:09:05.498Z"
   },
   {
    "duration": 858,
    "start_time": "2025-07-13T09:09:11.719Z"
   },
   {
    "duration": 15,
    "start_time": "2025-07-13T09:09:12.578Z"
   },
   {
    "duration": 150,
    "start_time": "2025-07-13T09:09:12.594Z"
   },
   {
    "duration": 450,
    "start_time": "2025-07-13T09:09:12.746Z"
   },
   {
    "duration": 520152,
    "start_time": "2025-07-13T09:09:13.198Z"
   },
   {
    "duration": 78,
    "start_time": "2025-07-13T09:17:53.352Z"
   },
   {
    "duration": 8104,
    "start_time": "2025-07-13T09:17:53.432Z"
   },
   {
    "duration": 10111244,
    "start_time": "2025-07-13T09:18:01.539Z"
   },
   {
    "duration": 21,
    "start_time": "2025-07-13T12:06:32.788Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
